{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:20.108099Z",
     "start_time": "2019-05-22T17:15:20.105608Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:19:04.996858Z",
     "start_time": "2019-05-22T17:19:04.994035Z"
    }
   },
   "outputs": [],
   "source": [
    "CURATED_ONLY = True # use only curated data for training\n",
    "USE_CLEAN_NOISY = True # Use clean noisy or dirty noisy\n",
    "TRAIN_AUGMENT = True # use augmentation for training data?\n",
    "MODEL = 'cnn8th' # choose among 'crnn', 'simple', 'cnn8th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:19:00.793232Z",
     "start_time": "2019-05-22T17:19:00.788408Z"
    }
   },
   "outputs": [],
   "source": [
    "SIZE=128\n",
    "EPOCHS = [303, 0, 0]\n",
    "TTA = [19, 0, 0]\n",
    "BATCH_SIZE = 32\n",
    "checkpoint_file = ['model_best1.h5', 'model_best2.h5', 'model_best3.h5']\n",
    "LR = 4e-4\n",
    "PATIENCE = 9 #ReduceOnPlateau option\n",
    "LR_FACTOR = 0.75 #ReduceOnPlateau option\n",
    "VALID_AUGMENT = False\n",
    "SEED = 1129\n",
    "USE_MIXUP = True\n",
    "MIXUP_PROB = 0.25\n",
    "\n",
    "SAMPLING_RATE = 44100  # 44.1[kHz]\n",
    "SAMPLE_DURATION = 2  # 2[sec]\n",
    "N_MEL = 128  # spectrogram y axis size\n",
    "FRAME_PER_SEC = N_MEL\n",
    "FFT_WINDOW_SIZE = 40\n",
    "SPEC_AUGMENTATION_RATE = 2\n",
    "\n",
    "# SPEC_AUGMENTATION\n",
    "NUM_MASK = 2\n",
    "FREQ_MASKING_MAX_PERCENTAGE = 0.15\n",
    "TIME_MASKING_MAX_PERCENTAGE = 0.30\n",
    "\n",
    "# No K-Fold implementation yet\n",
    "# NUM_K_FOLDS = 5 # how many folds (K) you gonna splits\n",
    "# NUM_MODEL_RUN = 5 # how many models (<= K) you gonna train [e.g. set to 1 for a simple train/test split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:22.791605Z",
     "start_time": "2019-05-22T17:15:22.789303Z"
    }
   },
   "outputs": [],
   "source": [
    "COMPETITION_DATASET_NAME = \"freesound-audio-tagging-2019\"\n",
    "PREPROCESSED_DATASET_NAME = \"fat2019_prep_mels1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:23.814878Z",
     "start_time": "2019-05-22T17:15:23.812675Z"
    }
   },
   "outputs": [],
   "source": [
    "ACTIVATION = 'linear' \n",
    "LOSS = 'BCEwithLogits' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:26.720273Z",
     "start_time": "2019-05-22T17:15:24.440904Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import librosa\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from functools import partial\n",
    "from inspect import currentframe\n",
    "from numba import jit\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from psutil import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:27.203716Z",
     "start_time": "2019-05-22T17:15:26.721999Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:20:38.928992Z",
     "start_time": "2019-05-22T17:20:38.925690Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobile\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.optimizers import Adam \n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:28.642149Z",
     "start_time": "2019-05-22T17:15:28.637572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility Cell\n",
    "def chkprint(*args):\n",
    "    def view_dir(dictionary):\n",
    "        string = \"\\n========\\n\"\n",
    "        for key, val in dictionary.items():\n",
    "             string += key + \":\\t\" + str(val) + \"\\n\"\n",
    "        string += \"--------------\\n\"\n",
    "        return string\n",
    "    names = {id(v):k for k,v in currentframe().f_back.f_locals.items()}\n",
    "    out =\"\"\n",
    "    for arg in args:\n",
    "        attr_name = names.get(id(arg))\n",
    "        out += attr_name + \": \"\n",
    "        if type(arg) == dict:\n",
    "            out += view_dir(arg)\n",
    "        else:\n",
    "            out += str(arg) + \"\\n\"\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:28.646374Z",
     "start_time": "2019-05-22T17:15:28.644012Z"
    }
   },
   "outputs": [],
   "source": [
    "IS_KERNEL = (\"local\" in os.uname()[1]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:28.810770Z",
     "start_time": "2019-05-22T17:15:28.807799Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\"..\") if IS_KERNEL else  Path(\".\").absolute().parents[0]\n",
    "dataset_dir = ROOT_PATH / \"input\" / COMPETITION_DATASET_NAME\n",
    "preprocessed_dir = ROOT_PATH / \"input\" / PREPROCESSED_DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:29.062960Z",
     "start_time": "2019-05-22T17:15:29.060018Z"
    }
   },
   "outputs": [],
   "source": [
    "HEAD = \"debug_\" if DEBUG_MODE else \"\"\n",
    "CURATED_DIR = HEAD + \"train_curated\"\n",
    "NOISY_DIR = HEAD + \"train_noisy\"\n",
    "TEST_DIR = HEAD + \"test\"\n",
    "SAMPLE_SUBMISSION = HEAD + \"sample_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:29.247262Z",
     "start_time": "2019-05-22T17:15:29.243648Z"
    }
   },
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / '{}.csv'.format(CURATED_DIR),\n",
    "    'train_noisy': dataset_dir / '{}.csv'.format(NOISY_DIR),\n",
    "    'clean_train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
    "    'sample_submission': dataset_dir / '{}.csv'.format(SAMPLE_SUBMISSION),\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    'train_curated': dataset_dir / 'train_curated',\n",
    "    'train_noisy': dataset_dir / 'train_noisy',\n",
    "    'test': dataset_dir / 'test',\n",
    "}\n",
    "\n",
    "mels = {\n",
    "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
    "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:29.424028Z",
     "start_time": "2019-05-22T17:15:29.420556Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dir: /Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019\n",
      "preprocessed_dir: /Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1\n",
      "HEAD: \n",
      "csvs: \n",
      "========\n",
      "train_curated:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_curated.csv\n",
      "train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_noisy.csv\n",
      "clean_train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1/trn_noisy_best50s.csv\n",
      "sample_submission:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/sample_submission.csv\n",
      "--------------\n",
      "dataset: \n",
      "========\n",
      "train_curated:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_curated\n",
      "train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_noisy\n",
      "test:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/test\n",
      "--------------\n",
      "mels: \n",
      "========\n",
      "train_curated:\t/Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1/mels_train_curated.pkl\n",
      "train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1/mels_trn_noisy_best50s.pkl\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utility Cell\n",
    "chkprint(dataset_dir, preprocessed_dir, HEAD, csvs, dataset, mels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:29.761865Z",
     "start_time": "2019-05-22T17:15:29.751327Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:29.945647Z",
     "start_time": "2019-05-22T17:15:29.942480Z"
    }
   },
   "outputs": [],
   "source": [
    "DataLoader = partial(DataLoader, num_workers=cpu_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Keras functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:30.450308Z",
     "start_time": "2019-05-22T17:15:30.440342Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/rio114/keras-cnn-with-lwlrap-evaluation/\n",
    "def tf_one_sample_positive_class_precisions(y_true, y_pred) :\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    \n",
    "    # find true labels\n",
    "    pos_class_indices = tf.where(y_true > 0) \n",
    "    \n",
    "    # put rank on each element\n",
    "    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n",
    "    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n",
    "    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n",
    "    sample_range = tf.transpose(sample_range)\n",
    "    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n",
    "    retrieved_class_map = tf.transpose(retrieved_class_map)\n",
    "    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n",
    "    \n",
    "    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n",
    "    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n",
    "    \n",
    "    class_rankings = tf.scatter_nd(retrieved_class_map,\n",
    "                                          class_range,\n",
    "                                          tf.shape(y_pred))\n",
    "    \n",
    "    #pick_up ranks\n",
    "    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n",
    "\n",
    "    # add one for division for \"presicion_at_hits\"\n",
    "    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n",
    "    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n",
    "    \n",
    "    # generate tensor [num_sample, predict_rank], \n",
    "    # top-N predicted elements have flag, N is the number of positive for each sample.\n",
    "    sample_label = pos_class_indices[:, 0]   \n",
    "    sample_label = tf.reshape(sample_label, (-1, 1))\n",
    "    sample_label = tf.cast(sample_label, tf.int32)\n",
    "    \n",
    "    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n",
    "    retrieved_class_true_position = tf.concat((sample_label, \n",
    "                                               num_correct_until_correct), axis=1)\n",
    "    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n",
    "    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n",
    "                                         retrieved_pos, \n",
    "                                         tf.shape(y_pred))\n",
    "    # cumulate predict_rank\n",
    "    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n",
    "\n",
    "    # find positive position\n",
    "    pos_ret_indices = tf.where(retrieved_class_true > 0)\n",
    "\n",
    "    # find cumulative hits\n",
    "    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n",
    "    correct_rank = tf.cast(correct_rank, tf.float32)\n",
    "\n",
    "    # compute presicion\n",
    "    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n",
    "\n",
    "    return pos_class_indices, precision_at_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:30.873959Z",
     "start_time": "2019-05-22T17:15:30.868714Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_lwlrap(y_true, y_pred):\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n",
    "    pos_flgs = tf.cast(y_true > 0, tf.int32)\n",
    "    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n",
    "    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n",
    "                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n",
    "    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n",
    "    class_label = pos_class_indices[:,1]\n",
    "    sum_precisions_by_classes = tf.unsorted_segment_sum(precision_at_hits,\n",
    "                                                        class_label,\n",
    "                                                       num_classes)\n",
    "    labels_per_class = tf.cast(labels_per_class, tf.float32)\n",
    "    labels_per_class = tf.add(labels_per_class, 1e-7)\n",
    "    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n",
    "                                  tf.cast(labels_per_class, tf.float32))\n",
    "    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:31.239986Z",
     "start_time": "2019-05-22T17:15:31.237016Z"
    }
   },
   "outputs": [],
   "source": [
    "def BCEwithLogits(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred, from_logits=True), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:32.162019Z",
     "start_time": "2019-05-22T17:15:32.116910Z"
    }
   },
   "outputs": [],
   "source": [
    "train_curated = pd.read_csv(csvs['train_curated'])\n",
    "noisy_name = \"clean_train_noisy\" if USE_CLEAN_NOISY else \"train_noisy\"\n",
    "train_noisy = pd.read_csv(csvs[noisy_name])\n",
    "train_df = train_curated\n",
    "if CURATED_ONLY is False:\n",
    "    train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
    "test_df = pd.read_csv(csvs['sample_submission'])\n",
    "labels = test_df.columns[1:].tolist()\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:34.651506Z",
     "start_time": "2019-05-22T17:15:34.611971Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname           labels\n",
       "0  0006ae4e.wav             Bark\n",
       "1  0019ef41.wav         Raindrop\n",
       "2  001ec0ad.wav  Finger_snapping\n",
       "3  0026c7cb.wav              Run\n",
       "4  0026f116.wav  Finger_snapping"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>singled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35688e71.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60d25862.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0f6fce9.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f3221561.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b2af1dc9.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                        labels  singled\n",
       "0  35688e71.wav  Bathtub_(filling_or_washing)     True\n",
       "1  60d25862.wav  Bathtub_(filling_or_washing)     True\n",
       "2  c0f6fce9.wav  Bathtub_(filling_or_washing)     True\n",
       "3  f3221561.wav  Bathtub_(filling_or_washing)     True\n",
       "4  b2af1dc9.wav  Bathtub_(filling_or_washing)     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
       "0  000ccb97.wav                                   0          0   \n",
       "1  0012633b.wav                                   0          0   \n",
       "2  001ed5f1.wav                                   0          0   \n",
       "3  00294be0.wav                                   0          0   \n",
       "4  003fde7a.wav                                   0          0   \n",
       "\n",
       "   Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
       "0                0         0     0          0            0   \n",
       "1                0         0     0          0            0   \n",
       "2                0         0     0          0            0   \n",
       "3                0         0     0          0            0   \n",
       "4                0         0     0          0            0   \n",
       "\n",
       "   Bathtub_(filling_or_washing)  Bicycle_bell        ...          \\\n",
       "0                             0             0        ...           \n",
       "1                             0             0        ...           \n",
       "2                             0             0        ...           \n",
       "3                             0             0        ...           \n",
       "4                             0             0        ...           \n",
       "\n",
       "   Toilet_flush  Traffic_noise_and_roadway_noise  Trickle_and_dribble  \\\n",
       "0             0                                0                    0   \n",
       "1             0                                0                    0   \n",
       "2             0                                0                    0   \n",
       "3             0                                0                    0   \n",
       "4             0                                0                    0   \n",
       "\n",
       "   Walk_and_footsteps  Water_tap_and_faucet  Waves_and_surf  Whispering  \\\n",
       "0                   0                     0               0           0   \n",
       "1                   0                     0               0           0   \n",
       "2                   0                     0               0           0   \n",
       "3                   0                     0               0           0   \n",
       "4                   0                     0               0           0   \n",
       "\n",
       "   Writing  Yell  Zipper_(clothing)  \n",
       "0        0     0                  0  \n",
       "1        0     0                  0  \n",
       "2        0     0                  0  \n",
       "3        0     0                  0  \n",
       "4        0     0                  0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Accelerating_and_revving_and_vroom',\n",
       " 'Accordion',\n",
       " 'Acoustic_guitar',\n",
       " 'Applause',\n",
       " 'Bark',\n",
       " 'Bass_drum',\n",
       " 'Bass_guitar',\n",
       " 'Bathtub_(filling_or_washing)',\n",
       " 'Bicycle_bell',\n",
       " 'Burping_and_eructation']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utility Cell\n",
    "display(train_curated.head(5))\n",
    "display(train_noisy.head(5))\n",
    "display(test_df.head(5))\n",
    "display(labels[:10])\n",
    "chkprint(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:35.593793Z",
     "start_time": "2019-05-22T17:15:35.504866Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
    "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
    "    for label in row:\n",
    "        idx = labels.index(label)\n",
    "        y_train[i, idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:37.312933Z",
     "start_time": "2019-05-22T17:15:36.184679Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
    "    x_train = pickle.load(curated)\n",
    "    if CURATED_ONLY == False:\n",
    "        x_train.extend(pickle.load(noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:15:37.872463Z",
     "start_time": "2019-05-22T17:15:37.869379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: (4970, 80)\n",
      "length of x_train: 4970\n"
     ]
    }
   ],
   "source": [
    "# Utility Cell\n",
    "print(\"y_train.shape: {}\".format(y_train.shape))\n",
    "print(\"length of x_train: {}\".format(len(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:16:46.501803Z",
     "start_time": "2019-05-22T17:16:46.498295Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_simple_block(x, n_filters):\n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:16:04.434905Z",
     "start_time": "2019-05-22T17:16:04.430954Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_simplecnn(n_out=num_classes):\n",
    "    inp = Input(shape=(128,128,3))\n",
    "    # np = Input(shape=(None,None,3))\n",
    "    x = conv_simple_block(inp,64)\n",
    "    x = conv_simple_block(x,128)\n",
    "    x = conv_simple_block(x,256)\n",
    "    x = conv_simple_block(x,128)\n",
    "    \n",
    "    # x1 = GlobalAveragePooling2D()(x)\n",
    "    # x2 = GlobalMaxPooling2D()(x)\n",
    "    # x = Add()([x1,x2])\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(128, activation='linear')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(n_out, activation=ACTIVATION)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:17:49.137882Z",
     "start_time": "2019-05-22T17:17:49.131540Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_of_lambda(input_shape):\n",
    "    return (input_shape[0], input_shape[2], input_shape[3])\n",
    "\n",
    "def my_max(x):\n",
    "    return K.max(x, axis=1, keepdims=False)\n",
    "\n",
    "def crnn_simple_block(x, n_filters):\n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def create_model_crnn(n_out= num_classes):\n",
    "    \n",
    "    # inp = Input(shape=(128,128,3))\n",
    "    inp = Input(shape=(128,None,3))\n",
    "    x = crnn_simple_block(inp,64)\n",
    "    x = crnn_simple_block(x,128)\n",
    "    x = crnn_simple_block(x,256)\n",
    "    \n",
    "    # eliminate the frequency dimension, x = (batch, time, channels)\n",
    "    x = Lambda(my_max, output_shape=output_of_lambda)(x)\n",
    "    \n",
    "    x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
    "    #  x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='linear')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(n_out, activation=ACTIVATION)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:18:33.403411Z",
     "start_time": "2019-05-22T17:18:33.395459Z"
    }
   },
   "outputs": [],
   "source": [
    "# from the 8th solution in 2018 competition\n",
    "# https://github.com/sainathadapa/kaggle-freesound-audio-tagging\n",
    "def create_model_cnn8th(n_out=num_classes):\n",
    "    regu=0\n",
    "    inp = Input(shape=(128,128,3))\n",
    "\n",
    "    x = Conv2D(48, 11,  strides=(1,1),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(48, 11,  strides=(2,3),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = MaxPooling2D(3, strides=(1,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(128, 5, strides=(1,1),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, 5, strides=(2,3),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(192, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(192, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = MaxPooling2D(3, strides=(1,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    predictions = Dense(n_out, activation=ACTIVATION)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T17:21:41.371865Z",
     "start_time": "2019-05-22T17:21:40.609108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "cnn8th\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 48)      17472     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 48)      192       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 43, 48)        278832    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 62, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 21, 128)       153728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 62, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 7, 128)        409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 15, 3, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 3, 192)        221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 3, 192)        768       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 3, 192)        331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 3, 192)        768       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 3, 128)        221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               426240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                20560     \n",
      "=================================================================\n",
      "Total params: 2,150,464\n",
      "Trainable params: 2,148,736\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "preprocess_input = preprocess_mobile\n",
    "if MODEL == 'crnn':\n",
    "    model = create_model_crnn(n_out=num_classes)\n",
    "elif MODEL == 'cnn8th':\n",
    "    model = create_model_cnn8th(n_out=num_classes)\n",
    "else:\n",
    "    model = create_model_simplecnn(n_out=num_classes)\n",
    "\n",
    "print(MODEL)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
