{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates\n",
    "- Add codes `_one_sample_positive_class_precisions` and `calculate_per_class_lwlrap`\n",
    "- Change `fmax`, which is a parameter of `librosa.feature.melspectrogram`, from `sr/2` to `sr // 2`\n",
    "- Change `CURATED_ONLY` from `True` to `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:45.937559Z",
     "start_time": "2019-05-23T15:50:45.934950Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T16:50:45.053329Z",
     "start_time": "2019-05-25T16:50:45.050607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use or not use\n",
    "CURATED_ONLY = False # use only curated data for training\n",
    "USE_CLEAN_NOISY = True # Use clean noisy or dirty noisy\n",
    "TRAIN_AUGMENT = True # use augmentation for training data?\n",
    "USE_KERNEL_DATASET = True\n",
    "MODEL = 'cnn8th' # choose among 'crnn', 'simple', 'cnn8th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T15:02:06.852200Z",
     "start_time": "2019-05-25T15:02:06.849911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config for librosa\n",
    "SAMPLING_RATE = 44100 # 44.1[kHz]\n",
    "SAMPLE_DURATION = 2    # 2[sec]\n",
    "N_MEL = 128  # spectrogram y axis size\n",
    "HOP_WINDOW = 347\n",
    "FFT_WINDOW_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:35:00.083604Z",
     "start_time": "2019-05-23T16:35:00.081045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spec Augmentation\n",
    "# Reference: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "NUM_MASK = 2\n",
    "FREQ_MASKING_MAX_PERCENTAGE = 0.15\n",
    "TIME_MASKING_MAX_PERCENTAGE = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:35:09.509293Z",
     "start_time": "2019-05-23T16:35:09.506574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "COMPETITION_DATASET_NAME = \"freesound-audio-tagging-2019\"\n",
    "PREPROCESSED_DATASET_NAME = \"fat2019_prep_mels1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:35:18.993114Z",
     "start_time": "2019-05-23T16:35:18.990239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "ACTIVATION = 'linear' \n",
    "LOSS = 'BCEwithLogits' \n",
    "LR = 4e-4\n",
    "PATIENCE = 9 #ReduceOnPlateau option\n",
    "LR_FACTOR = 0.75 #ReduceOnPlateau option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:35:35.751667Z",
     "start_time": "2019-05-23T16:35:35.748519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Other configs\n",
    "SEED = 520\n",
    "SIZE=128\n",
    "EPOCHS = [303, 0, 0]\n",
    "TTA = [19, 0, 0]\n",
    "checkpoint_file = ['model_best1.h5', 'model_best2.h5', 'model_best3.h5']\n",
    "VALID_AUGMENT = False\n",
    "USE_MIXUP = True\n",
    "MIXUP_PROB = 0.25\n",
    "\n",
    "# No K-Fold implementation yet\n",
    "# NUM_K_FOLDS = 5 # how many folds (K) you gonna splits\n",
    "# NUM_MODEL_RUN = 5 # how many models (<= K) you gonna train [e.g. set to 1 for a simple train/test split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:27:29.458519Z",
     "start_time": "2019-05-23T17:27:29.452612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import librosa\n",
    "import sklearn.metrics\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from functools import partial\n",
    "from imgaug import augmenters as iaa\n",
    "from inspect import currentframe\n",
    "from numba import jit\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from psutil import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobile\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.optimizers import Adam \n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:54.872616Z",
     "start_time": "2019-05-23T15:50:54.868322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility Cell\n",
    "def chkprint(*args):\n",
    "    def view_dir(dictionary):\n",
    "        string = \"\\n========\\n\"\n",
    "        for key, val in dictionary.items():\n",
    "             string += key + \":\\t\" + str(val) + \"\\n\"\n",
    "        string += \"--------------\\n\"\n",
    "        return string\n",
    "    names = {id(v):k for k,v in currentframe().f_back.f_locals.items()}\n",
    "    out =\"\"\n",
    "    for arg in args:\n",
    "        attr_name = names.get(id(arg))\n",
    "        out += attr_name + \": \"\n",
    "        if type(arg) == dict:\n",
    "            out += view_dir(arg)\n",
    "        else:\n",
    "            out += str(arg) + \"\\n\"\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:59:30.651804Z",
     "start_time": "2019-05-23T16:59:30.648666Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_as_pkl_binary(obj, filename):\n",
    "    \"\"\"Save object as pickle binary file.\n",
    "    Thanks to https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-file/32216025\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:59:39.264064Z",
     "start_time": "2019-05-23T16:59:39.260948Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pkl(filename):\n",
    "    \"\"\"Load pickle object from file.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:54.877407Z",
     "start_time": "2019-05-23T15:50:54.874794Z"
    }
   },
   "outputs": [],
   "source": [
    "IS_KERNEL = (\"local\" in os.uname()[1]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:54.882215Z",
     "start_time": "2019-05-23T15:50:54.879377Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\"..\") if IS_KERNEL else  Path(\".\").absolute().parents[0]\n",
    "dataset_dir = ROOT_PATH / \"input\" / COMPETITION_DATASET_NAME\n",
    "preprocessed_dir = ROOT_PATH / \"input\" / PREPROCESSED_DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:55.921799Z",
     "start_time": "2019-05-23T15:50:55.918876Z"
    }
   },
   "outputs": [],
   "source": [
    "HEAD = \"debug_\" if DEBUG_MODE else \"\"\n",
    "CURATED_DIR = HEAD + \"train_curated\"\n",
    "NOISY_DIR = HEAD + \"train_noisy\"\n",
    "TEST_DIR = HEAD + \"test\"\n",
    "SAMPLE_SUBMISSION = HEAD + \"sample_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:30:52.069654Z",
     "start_time": "2019-05-23T16:30:52.065403Z"
    }
   },
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / '{}.csv'.format(CURATED_DIR),\n",
    "    'train_noisy': dataset_dir / '{}.csv'.format(NOISY_DIR),\n",
    "    'clean_train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
    "    'sample_submission': dataset_dir / '{}.csv'.format(SAMPLE_SUBMISSION),\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    'train_curated': dataset_dir / CURATED_DIR,\n",
    "    'train_noisy': dataset_dir / NOISY_DIR,\n",
    "    'test': dataset_dir / TEST_DIR,\n",
    "}\n",
    "\n",
    "mels = {\n",
    "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
    "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:56.971665Z",
     "start_time": "2019-05-23T15:50:56.967811Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dir: /Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019\n",
      "preprocessed_dir: /Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1\n",
      "HEAD: \n",
      "csvs: \n",
      "========\n",
      "train_curated:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_curated.csv\n",
      "train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_noisy.csv\n",
      "clean_train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1/trn_noisy_best50s.csv\n",
      "sample_submission:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/sample_submission.csv\n",
      "--------------\n",
      "dataset: \n",
      "========\n",
      "train_curated:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_curated\n",
      "train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/train_noisy\n",
      "test:\t/Users/berry/Kaggle/kaggle_freesound/input/freesound-audio-tagging-2019/test\n",
      "--------------\n",
      "mels: \n",
      "========\n",
      "train_curated:\t/Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1/mels_train_curated.pkl\n",
      "train_noisy:\t/Users/berry/Kaggle/kaggle_freesound/input/fat2019_prep_mels1/mels_trn_noisy_best50s.pkl\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utility Cell\n",
    "chkprint(dataset_dir, preprocessed_dir, HEAD, csvs, dataset, mels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:58.129471Z",
     "start_time": "2019-05-23T15:50:58.118695Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:58.529451Z",
     "start_time": "2019-05-23T15:50:58.526713Z"
    }
   },
   "outputs": [],
   "source": [
    "DataLoader = partial(DataLoader, num_workers=cpu_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:51:02.390785Z",
     "start_time": "2019-05-23T15:51:02.345690Z"
    }
   },
   "outputs": [],
   "source": [
    "train_curated = pd.read_csv(csvs['train_curated'])\n",
    "noisy_name = \"clean_train_noisy\" if USE_CLEAN_NOISY else \"train_noisy\"\n",
    "train_noisy = pd.read_csv(csvs[noisy_name])\n",
    "train_df = train_curated\n",
    "if CURATED_ONLY is False:\n",
    "    train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
    "test_df = pd.read_csv(csvs['sample_submission'])\n",
    "labels = test_df.columns[1:].tolist()\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:33:23.762317Z",
     "start_time": "2019-05-23T16:33:23.730416Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname           labels\n",
       "0  0006ae4e.wav             Bark\n",
       "1  0019ef41.wav         Raindrop\n",
       "2  001ec0ad.wav  Finger_snapping\n",
       "3  0026c7cb.wav              Run\n",
       "4  0026f116.wav  Finger_snapping"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>singled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35688e71.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60d25862.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0f6fce9.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f3221561.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b2af1dc9.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                        labels  singled\n",
       "0  35688e71.wav  Bathtub_(filling_or_washing)     True\n",
       "1  60d25862.wav  Bathtub_(filling_or_washing)     True\n",
       "2  c0f6fce9.wav  Bathtub_(filling_or_washing)     True\n",
       "3  f3221561.wav  Bathtub_(filling_or_washing)     True\n",
       "4  b2af1dc9.wav  Bathtub_(filling_or_washing)     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
       "0  000ccb97.wav                                   0          0   \n",
       "1  0012633b.wav                                   0          0   \n",
       "2  001ed5f1.wav                                   0          0   \n",
       "3  00294be0.wav                                   0          0   \n",
       "4  003fde7a.wav                                   0          0   \n",
       "\n",
       "   Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
       "0                0         0     0          0            0   \n",
       "1                0         0     0          0            0   \n",
       "2                0         0     0          0            0   \n",
       "3                0         0     0          0            0   \n",
       "4                0         0     0          0            0   \n",
       "\n",
       "   Bathtub_(filling_or_washing)  Bicycle_bell        ...          \\\n",
       "0                             0             0        ...           \n",
       "1                             0             0        ...           \n",
       "2                             0             0        ...           \n",
       "3                             0             0        ...           \n",
       "4                             0             0        ...           \n",
       "\n",
       "   Toilet_flush  Traffic_noise_and_roadway_noise  Trickle_and_dribble  \\\n",
       "0             0                                0                    0   \n",
       "1             0                                0                    0   \n",
       "2             0                                0                    0   \n",
       "3             0                                0                    0   \n",
       "4             0                                0                    0   \n",
       "\n",
       "   Walk_and_footsteps  Water_tap_and_faucet  Waves_and_surf  Whispering  \\\n",
       "0                   0                     0               0           0   \n",
       "1                   0                     0               0           0   \n",
       "2                   0                     0               0           0   \n",
       "3                   0                     0               0           0   \n",
       "4                   0                     0               0           0   \n",
       "\n",
       "   Writing  Yell  Zipper_(clothing)  \n",
       "0        0     0                  0  \n",
       "1        0     0                  0  \n",
       "2        0     0                  0  \n",
       "3        0     0                  0  \n",
       "4        0     0                  0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Accelerating_and_revving_and_vroom',\n",
       " 'Accordion',\n",
       " 'Acoustic_guitar',\n",
       " 'Applause',\n",
       " 'Bark',\n",
       " 'Bass_drum',\n",
       " 'Bass_guitar',\n",
       " 'Bathtub_(filling_or_washing)',\n",
       " 'Bicycle_bell',\n",
       " 'Burping_and_eructation']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utility Cell\n",
    "display(train_curated.head(5))\n",
    "display(train_noisy.head(5))\n",
    "display(test_df.head(5))\n",
    "display(labels[:10])\n",
    "chkprint(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:51:06.822069Z",
     "start_time": "2019-05-23T15:51:06.807404Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
    "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
    "    for label in row:\n",
    "        idx = labels.index(label)\n",
    "        y_train[i, idx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:58:05.903625Z",
     "start_time": "2019-05-23T16:58:05.899558Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_audio(wav_path):\n",
    "    y, _= librosa.load(wav_path, sr=SAMPLING_RATE)\n",
    "\n",
    "    # trim silence : https://librosa.github.io/librosa/generated/librosa.effects.trim.html\n",
    "    if 0 < len(y):\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "\n",
    "    # padding short data\n",
    "    sample_size = SAMPLE_DURATION * SAMPLING_RATE\n",
    "    if len(y) < sample_size:\n",
    "        padding = sample_size - len(y)\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, sample_size - len(y) - offset), \"constant\")\n",
    "\n",
    "    return y  # np.ndarrya, shape=(sample_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:58:06.385786Z",
     "start_time": "2019-05-23T16:58:06.380858Z"
    }
   },
   "outputs": [],
   "source": [
    "def audio_to_melspectrogram(audio, sr=SAMPLING_RATE):\n",
    "    spectrogram = librosa.feature.melspectrogram(\n",
    "        audio,\n",
    "        sr=sr,\n",
    "        n_mels=N_MEL,           # https://librosa.github.io/librosa/generated/librosa.filters.mel.html#librosa.filters.mel\n",
    "        hop_length= SAMPLE_DURATION * HOP_WINDOW,  # to make time steps 128\n",
    "        n_fft=N_MEL * FFT_WINDOW_SIZE,\n",
    "        fmin=20,                # Filterbank lowest frequency, Audible range 20[Hz]\n",
    "        fmax=sr // 2             # Nyquist frequency\n",
    "    )\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:58:06.704435Z",
     "start_time": "2019-05-23T16:58:06.700749Z"
    }
   },
   "outputs": [],
   "source": [
    "def mono_to_color(mono):\n",
    "    # stack X as [mono, mono, mono]\n",
    "    x = np.stack([mono, mono, mono], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    x_std = (x - x.mean()) / (x.std() + 1e-6)\n",
    "\n",
    "    if (x_std.max() - x_std.min()) > 1e-6:\n",
    "        color = 255 * (x_std - x_std.min()) / (x_std.max() - x_std.min())\n",
    "        color = color.astype(np.uint8)\n",
    "    else:\n",
    "        color = np.zeros_like(x_std, dtype=np.uint8)\n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:58:07.095825Z",
     "start_time": "2019-05-23T16:58:07.092996Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_as_melspectrogram(pathname):\n",
    "    x = read_audio(pathname)\n",
    "    return audio_to_melspectrogram(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:58:07.609027Z",
     "start_time": "2019-05-23T16:58:07.605648Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_wav_to_image(df, source):\n",
    "    X = []\n",
    "    for i, row in df.iterrows():\n",
    "        x = read_as_melspectrogram(source / str(row.fname))\n",
    "        x_color = mono_to_color(x)\n",
    "        X.append(x_color)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:11:45.344638Z",
     "start_time": "2019-05-23T17:11:45.339510Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_best_50s_noisy(x_noisy):\n",
    "    df = x_noisy.copy()\n",
    "    df['singled'] = ~df.labels.str.contains(',')\n",
    "    singles_df = df[df.singled]\n",
    "    \n",
    "    cat_gp = (singles_df.groupby(\n",
    "        ['labels']).agg({\n",
    "        'fname':'count'\n",
    "    }).reset_index()).set_index('labels')\n",
    "    labels = singles_df.labels.unique()\n",
    "    \n",
    "    idxes_best50s = np.array([random.choices(singles_df[(singles_df.labels == l)].index, k=50) for l in labels]).ravel()\n",
    "    best50s_df = singles_df.loc[idxes_best50s]\n",
    "    return best50s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat curated and noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T16:59:23.406481Z",
     "start_time": "2019-05-23T16:58:07.954561Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test =  convert_wav_to_image(test_df, dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:10.720004Z",
     "start_time": "2019-05-23T15:50:09.400407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use kernel data\n",
    "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
    "    x_train = pickle.load(curated)\n",
    "    if CURATED_ONLY == False:\n",
    "        x_train.extend(pickle.load(noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:08:35.611321Z",
     "start_time": "2019-05-23T17:08:34.023000Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_KERNEL_DATASET:\n",
    "    x_train = load_pkl(mels[\"train_curated\"])\n",
    "    if CURATED_ONLY == False:\n",
    "        x_train.extend(load_pkl(mels[\"train_noisy\"]))\n",
    "else:\n",
    "    x_trainn = convert_wav_to_image(train_curated)\n",
    "    if CURATED_ONLY == False:\n",
    "        x_noisy = convert_wav_to_image(train_noisy)\n",
    "        x_train.extend(x_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:06:04.572841Z",
     "start_time": "2019-05-23T17:06:04.569827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: (4970, 80)\n",
      "length of x_train: 4970\n"
     ]
    }
   ],
   "source": [
    "# Utility Cell\n",
    "print(\"y_train.shape: {}\".format(y_train.shape))\n",
    "print(\"length of x_train: {}\".format(len(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Definition of Keras functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:50:59.512177Z",
     "start_time": "2019-05-23T15:50:59.501804Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/rio114/keras-cnn-with-lwlrap-evaluation/\n",
    "def tf_one_sample_positive_class_precisions(y_true, y_pred) :\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    \n",
    "    # find true labels\n",
    "    pos_class_indices = tf.where(y_true > 0) \n",
    "    \n",
    "    # put rank on each element\n",
    "    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n",
    "    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n",
    "    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n",
    "    sample_range = tf.transpose(sample_range)\n",
    "    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n",
    "    retrieved_class_map = tf.transpose(retrieved_class_map)\n",
    "    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n",
    "    \n",
    "    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n",
    "    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n",
    "    \n",
    "    class_rankings = tf.scatter_nd(retrieved_class_map,\n",
    "                                          class_range,\n",
    "                                          tf.shape(y_pred))\n",
    "    \n",
    "    #pick_up ranks\n",
    "    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n",
    "\n",
    "    # add one for division for \"presicion_at_hits\"\n",
    "    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n",
    "    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n",
    "    \n",
    "    # generate tensor [num_sample, predict_rank], \n",
    "    # top-N predicted elements have flag, N is the number of positive for each sample.\n",
    "    sample_label = pos_class_indices[:, 0]   \n",
    "    sample_label = tf.reshape(sample_label, (-1, 1))\n",
    "    sample_label = tf.cast(sample_label, tf.int32)\n",
    "    \n",
    "    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n",
    "    retrieved_class_true_position = tf.concat((sample_label, \n",
    "                                               num_correct_until_correct), axis=1)\n",
    "    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n",
    "    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n",
    "                                         retrieved_pos, \n",
    "                                         tf.shape(y_pred))\n",
    "    # cumulate predict_rank\n",
    "    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n",
    "\n",
    "    # find positive position\n",
    "    pos_ret_indices = tf.where(retrieved_class_true > 0)\n",
    "\n",
    "    # find cumulative hits\n",
    "    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n",
    "    correct_rank = tf.cast(correct_rank, tf.float32)\n",
    "\n",
    "    # compute presicion\n",
    "    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n",
    "\n",
    "    return pos_class_indices, precision_at_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:51:00.524441Z",
     "start_time": "2019-05-23T15:51:00.518387Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_lwlrap(y_true, y_pred):\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n",
    "    pos_flgs = tf.cast(y_true > 0, tf.int32)\n",
    "    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n",
    "    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n",
    "                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n",
    "    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n",
    "    class_label = pos_class_indices[:,1]\n",
    "    sum_precisions_by_classes = tf.unsorted_segment_sum(precision_at_hits,\n",
    "                                                        class_label,\n",
    "                                                       num_classes)\n",
    "    labels_per_class = tf.cast(labels_per_class, tf.float32)\n",
    "    labels_per_class = tf.add(labels_per_class, 1e-7)\n",
    "    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n",
    "                                  tf.cast(labels_per_class, tf.float32))\n",
    "    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:51:01.469798Z",
     "start_time": "2019-05-23T15:51:01.466413Z"
    }
   },
   "outputs": [],
   "source": [
    "def BCEwithLogits(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred, from_logits=True), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:37:48.361303Z",
     "start_time": "2019-05-23T15:37:48.357848Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_simple_block(x, n_filters):\n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:37:48.533413Z",
     "start_time": "2019-05-23T15:37:48.528999Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_simplecnn(n_out=num_classes):\n",
    "    inp = Input(shape=(128,128,3))\n",
    "    # np = Input(shape=(None,None,3))\n",
    "    x = conv_simple_block(inp,64)\n",
    "    x = conv_simple_block(x,128)\n",
    "    x = conv_simple_block(x,256)\n",
    "    x = conv_simple_block(x,128)\n",
    "    \n",
    "    # x1 = GlobalAveragePooling2D()(x)\n",
    "    # x2 = GlobalMaxPooling2D()(x)\n",
    "    # x = Add()([x1,x2])\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(128, activation='linear')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(n_out, activation=ACTIVATION)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:37:48.912950Z",
     "start_time": "2019-05-23T15:37:48.907588Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_of_lambda(input_shape):\n",
    "    return (input_shape[0], input_shape[2], input_shape[3])\n",
    "\n",
    "def my_max(x):\n",
    "    return K.max(x, axis=1, keepdims=False)\n",
    "\n",
    "def crnn_simple_block(x, n_filters):\n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Convolution2D(n_filters, (3,1), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def create_model_crnn(n_out= num_classes):\n",
    "    \n",
    "    # inp = Input(shape=(128,128,3))\n",
    "    inp = Input(shape=(128,None,3))\n",
    "    x = crnn_simple_block(inp,64)\n",
    "    x = crnn_simple_block(x,128)\n",
    "    x = crnn_simple_block(x,256)\n",
    "    \n",
    "    # eliminate the frequency dimension, x = (batch, time, channels)\n",
    "    x = Lambda(my_max, output_shape=output_of_lambda)(x)\n",
    "    \n",
    "    x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
    "    #  x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='linear')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(n_out, activation=ACTIVATION)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:22:37.603393Z",
     "start_time": "2019-05-23T17:22:37.594838Z"
    }
   },
   "outputs": [],
   "source": [
    "# from the 8th solution in 2018 competition\n",
    "# https://github.com/sainathadapa/kaggle-freesound-audio-tagging\n",
    "def create_model_cnn8th(n_out=num_classes):\n",
    "    regu=0\n",
    "    inp = Input(shape=(128,128,3))\n",
    "\n",
    "    x = Conv2D(48, 11,  strides=(1,1),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(48, 11,  strides=(2,3),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = MaxPooling2D(3, strides=(1,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(128, 5, strides=(1,1),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, 5, strides=(2,3),kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(192, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(192, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same',kernel_regularizer=regularizers.l2(regu))(x)\n",
    "    x = MaxPooling2D(3, strides=(1,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    predictions = Dense(n_out, activation=ACTIVATION)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:22:39.086372Z",
     "start_time": "2019-05-23T17:22:38.302774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "cnn8th\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 48)      17472     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 48)      192       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 43, 48)        278832    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 62, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 21, 128)       153728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 62, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 7, 128)        409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 15, 3, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 3, 192)        221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 3, 192)        768       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 3, 192)        331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 3, 192)        768       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 3, 128)        221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               426240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                20560     \n",
      "=================================================================\n",
      "Total params: 2,150,464\n",
      "Trainable params: 2,148,736\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "preprocess_input = preprocess_mobile\n",
    "if MODEL == 'crnn':\n",
    "    model = create_model_crnn(n_out=num_classes)\n",
    "elif MODEL == 'cnn8th':\n",
    "    model = create_model_cnn8th(n_out=num_classes)\n",
    "else:\n",
    "    model = create_model_simplecnn(n_out=num_classes)\n",
    "\n",
    "print(MODEL)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T15:56:09.560624Z",
     "start_time": "2019-05-23T15:56:09.555585Z"
    }
   },
   "outputs": [],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=2,\n",
    "                 freq_masking_max_percentage=0.15, time_masking_max_percentage=0.3):\n",
    "    \"\"\"Simple augmentation using cross masks\n",
    "    Reference: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    \"\"\"\n",
    "    spec = spec.copy()\n",
    "\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:17:57.003816Z",
     "start_time": "2019-05-23T17:17:56.999401Z"
    }
   },
   "outputs": [],
   "source": [
    "augment_img = iaa.Sequential([\n",
    "    # iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    # iaa.Multiply((0.9, 1.1), per_channel=0.2),\n",
    "    iaa.Fliplr(0.5),\n",
    "    # iaa.GaussianBlur(sigma=(0, 0.1)),\n",
    "    # iaa.Affine( # x-shift\n",
    "    #     translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.0, 0.0)},\n",
    "    #  ),\n",
    "    iaa.CoarseDropout(0.12,size_percent=0.05) # see examples : https://github.com/aleju/imgaug\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:19:54.536033Z",
     "start_time": "2019-05-23T17:19:54.527160Z"
    }
   },
   "outputs": [],
   "source": [
    "class FATTrainDataset(Sequence):\n",
    "\n",
    "    def mix_up(x, y):\n",
    "        x = np.array(x, np.float32)\n",
    "        lam = np.random.beta(1.0, 1.0)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "    \n",
    "    def getitem(image):\n",
    "        # crop 2sec\n",
    "\n",
    "        base_dim, time_dim, _ = image.shape\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image[:,crop:crop+base_dim,:]\n",
    "\n",
    "        image = preprocess_input(image)\n",
    "        # label = self.labels[idx]\n",
    "        return image\n",
    "\n",
    "    def create_generator(train_X, train_y, batch_size, shape, augument=False, shuffling=False, test_data=False, mixup=False, mixup_prob=0.3):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            if shuffling:\n",
    "                train_X,train_y = shuffle(train_X,train_y)\n",
    "\n",
    "            for start in range(0, len(train_y), batch_size):\n",
    "                end = min(start + batch_size, len(train_y))\n",
    "                batch_images = []\n",
    "                X_train_batch = train_X[start:end]\n",
    "                if test_data == False:\n",
    "                    batch_labels = train_y[start:end]\n",
    "                \n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = FATTrainDataset.getitem(X_train_batch[i])   \n",
    "                    if augument:\n",
    "                        image = FATTrainDataset.augment(image)\n",
    "                    batch_images.append(image)\n",
    "                \n",
    "                if (mixup and test_data == False):\n",
    "                    dice = np.random.rand(1)\n",
    "                    if dice > mixup_prob:\n",
    "                        batch_images, batch_labels =  FATTrainDataset.mix_up(batch_images, batch_labels)    \n",
    "                    \n",
    "                if test_data == False:\n",
    "                    yield np.array(batch_images, np.float32), batch_labels\n",
    "                else:\n",
    "                    yield np.array(batch_images, np.float32)\n",
    "        return image\n",
    "    \n",
    "    def augment(image):\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:24:16.554001Z",
     "start_time": "2019-05-23T17:24:16.550309Z"
    }
   },
   "outputs": [],
   "source": [
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_tf_lwlrap', factor=LR_FACTOR, patience=PATIENCE, \n",
    "                                   verbose=1, mode='max', min_delta=0.0001, cooldown=2, min_lr=1e-5 )\n",
    "checkpoint = ModelCheckpoint(checkpoint_file[0], monitor='val_tf_lwlrap', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "callbacks_list = [checkpoint, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:21:37.624634Z",
     "start_time": "2019-05-23T17:21:37.607607Z"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train, valid\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = FATTrainDataset.create_generator(\n",
    "    x_trn, y_trn, BATCH_SIZE, (SIZE,SIZE,3), augument=TRAIN_AUGMENT, shuffling=True, mixup = USE_MIXUP, mixup_prob = MIXUP_PROB)\n",
    "validation_generator = FATTrainDataset.create_generator(\n",
    "    x_val, y_val, BATCH_SIZE, (SIZE,SIZE,3), augument=VALID_AUGMENT, shuffling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:21:46.266981Z",
     "start_time": "2019-05-23T17:21:46.262951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 32\n",
      "3976\n"
     ]
    }
   ],
   "source": [
    "train_steps = np.ceil(float(len(x_trn)) / float(BATCH_SIZE))\n",
    "val_steps = np.ceil(float(len(x_val)) / float(BATCH_SIZE))\n",
    "train_steps = train_steps.astype(int)\n",
    "val_steps = val_steps.astype(int)\n",
    "print(train_steps, val_steps)\n",
    "print(len(x_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:22:43.053261Z",
     "start_time": "2019-05-23T17:22:42.899205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCEwithLogits\n"
     ]
    }
   ],
   "source": [
    "print(LOSS)\n",
    "if LOSS=='BCEwithLogits':\n",
    "     model.compile(loss=BCEwithLogits,\n",
    "            optimizer=Adam(lr=LR),\n",
    "            metrics=[tf_lwlrap,'categorical_accuracy'])\n",
    "else:\n",
    "    model.compile(loss=LOSS,\n",
    "            optimizer=Adam(lr=LR),\n",
    "            metrics=[tf_lwlrap,'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:24:18.281081Z",
     "start_time": "2019-05-23T17:24:18.277013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004 9 0.75 32 True True 0.25\n"
     ]
    }
   ],
   "source": [
    "print(LR, PATIENCE, LR_FACTOR,BATCH_SIZE, TRAIN_AUGMENT, USE_MIXUP, MIXUP_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:24:25.047709Z",
     "start_time": "2019-05-23T17:24:18.796487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-bcdeeb438f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=EPOCHS[0],\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:24:33.752513Z",
     "start_time": "2019-05-23T17:24:33.703253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:24:49.738254Z",
     "start_time": "2019-05-23T17:24:49.733932Z"
    }
   },
   "outputs": [],
   "source": [
    "if EPOCHS[1] > 0:\n",
    "    checkpoint = ModelCheckpoint(checkpoint_file[1], monitor='val_tf_lwlrap', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "    callbacks_list = [checkpoint, csv_logger, reduceLROnPlat]\n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=EPOCHS[1],\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:24:56.700056Z",
     "start_time": "2019-05-23T17:24:56.696175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:25:03.560726Z",
     "start_time": "2019-05-23T17:25:03.556413Z"
    }
   },
   "outputs": [],
   "source": [
    "if EPOCHS[2] > 0:\n",
    "    checkpoint = ModelCheckpoint(checkpoint_file[2], monitor='val_tf_lwlrap', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "    callbacks_list = [checkpoint, csv_logger, reduceLROnPlat]\n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=EPOCHS[2],\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:25:10.656927Z",
     "start_time": "2019-05-23T17:25:10.652873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:25:49.505270Z",
     "start_time": "2019-05-23T17:25:49.263010Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-6dfcef895781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('categorical_accuracy')\n",
    "ax[1].plot(hist.epoch, hist.history[\"categorical_accuracy\"], label=\"Train categorical_accuracy\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_categorical_accuracy\"], label=\"Validation categorical_accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:26:06.691939Z",
     "start_time": "2019-05-23T17:26:06.476256Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-3672809d249b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tf_lwlrap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf_lwlrap\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train lwlrap\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_tf_lwlrap\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation lwlrap\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('tf_lwlrap')\n",
    "ax[0].plot(hist.epoch, hist.history[\"tf_lwlrap\"], label=\"Train lwlrap\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_tf_lwlrap\"], label=\"Validation lwlrap\")\n",
    "ax[1].set_title('categorical_accuracy')\n",
    "ax[1].plot(hist.epoch, hist.history[\"categorical_accuracy\"], label=\"Train categorical_accuracy\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_categorical_accuracy\"], label=\"Validation categorical_accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:26:23.524439Z",
     "start_time": "2019-05-23T17:26:23.341389Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model_best1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-42e550bbe889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m validation_generator = FATTrainDataset.create_generator(\n\u001b[1;32m      4\u001b[0m       x_val, y_val, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False)\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_val_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model_best1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_file[0])\n",
    "\n",
    "validation_generator = FATTrainDataset.create_generator(\n",
    "      x_val, y_val, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False)\n",
    "pred_val_y = model.predict_generator(validation_generator,steps=val_steps,verbose=1)\n",
    "\n",
    "for kk in range(len(TTA)):\n",
    "    \n",
    "    for ii in range(TTA[kk]):\n",
    "        validation_generator = FATTrainDataset.create_generator(\n",
    "          x_val, y_val, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False)\n",
    "        \n",
    "        pred_val_y += model.predict_generator(validation_generator,steps=val_steps,verbose=1)\n",
    "    \n",
    "    if kk+1 < len(TTA) and TTA[kk+1] > 0:\n",
    "        model.load_weights(checkpoint_file[kk+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:26:51.330003Z",
     "start_time": "2019-05-23T17:26:44.304641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/125 [>.............................] - ETA: 2:20"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-8181267d93d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_generator = FATTrainDataset.create_generator(\n\u001b[1;32m      2\u001b[0m     x_trn, y_trn, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred_train_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator = FATTrainDataset.create_generator(\n",
    "    x_trn, y_trn, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False)\n",
    "pred_train_y = model.predict_generator(train_generator,steps=train_steps,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T16:45:11.475298Z",
     "start_time": "2019-05-25T16:45:11.469440Z"
    }
   },
   "outputs": [],
   "source": [
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T16:45:11.885067Z",
     "start_time": "2019-05-25T16:45:11.878985Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:27:04.885570Z",
     "start_time": "2019-05-23T17:27:04.881613Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "    sample_weight = np.sum(truth > 0, axis=1)\n",
    "    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "    overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0, \n",
    "      scores[nonzero_weight_sample_indices, :], \n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "    return overall_lwlrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:27:43.577539Z",
     "start_time": "2019-05-23T17:27:43.558683Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_train_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-53a6868ee162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lwlrap from sklearn.metrics for training data =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_overall_lwlrap_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val lwlrap from sklearn.metrics =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_overall_lwlrap_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val_y\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_per_class_lwlrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlwlrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_train_y' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"lwlrap from sklearn.metrics for training data =\", calculate_overall_lwlrap_sklearn(y_trn, pred_train_y))\n",
    "print(\"val lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(y_val, pred_val_y/10))\n",
    "\n",
    "score, weight = calculate_per_class_lwlrap(y_val, pred_val_y)\n",
    "lwlrap = (score * weight).sum()\n",
    "print('direct calculation of val lwlrap : %.4f' % (lwlrap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:28:09.762059Z",
     "start_time": "2019-05-23T17:28:09.742976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 80) (852, 80)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_val_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-3e34576c36f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val lwlrap for multi-labels =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_overall_lwlrap_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val lwlrap for single-label =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_overall_lwlrap_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_val_y' is not defined"
     ]
    }
   ],
   "source": [
    "idx = np.sum(y_val,axis=1) > 1\n",
    "print(y_val[idx, :].shape, y_val[idx==False, :].shape)\n",
    "\n",
    "print(\"val lwlrap for multi-labels =\", calculate_overall_lwlrap_sklearn(y_val[idx], pred_val_y[idx]))\n",
    "print(\"val lwlrap for single-label =\", calculate_overall_lwlrap_sklearn(y_val[idx==False], pred_val_y[idx==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Data with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:28:36.469644Z",
     "start_time": "2019-05-23T17:28:36.467059Z"
    }
   },
   "outputs": [],
   "source": [
    "test_steps = np.ceil(float(len(x_test)) / float(BATCH_SIZE)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:28:42.756909Z",
     "start_time": "2019-05-23T17:28:42.704021Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model_best1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-37db0dbc3adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m test_generator = FATTrainDataset.create_generator(\n\u001b[1;32m      4\u001b[0m     x_test, x_test, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False, test_data=True)\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model_best1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_file[0])\n",
    "\n",
    "test_generator = FATTrainDataset.create_generator(\n",
    "    x_test, x_test, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False, test_data=True)\n",
    "pred_test_y = model.predict_generator(test_generator,steps=test_steps,verbose=1)\n",
    "\n",
    "for kk in range(len(TTA)):\n",
    "    for ii in range(TTA[kk]):\n",
    "        test_generator = FATTrainDataset.create_generator(\n",
    "        x_test, x_test, BATCH_SIZE, (SIZE,SIZE,3), augument=False, shuffling=False, test_data=True)\n",
    "        \n",
    "        pred_test_y += model.predict_generator(test_generator,steps=test_steps,verbose=1)\n",
    "    \n",
    "    if kk+1 < len(TTA) and TTA[kk+1] > 0:\n",
    "        model.load_weights(checkpoint_file[kk+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:29:06.640957Z",
     "start_time": "2019-05-23T17:29:06.637367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79]\n"
     ]
    }
   ],
   "source": [
    "sort_idx = np.argsort(labels).astype(int)\n",
    "print(sort_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T17:29:21.025980Z",
     "start_time": "2019-05-23T17:29:20.988152Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-716922ee040c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/freesound-audio-tagging-2019/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_Y_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_test_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtest_Y_sort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_test_y' is not defined"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../input/freesound-audio-tagging-2019/sample_submission.csv')\n",
    "test_Y_sort = pred_test_y[:, sort_idx]\n",
    "sample_sub.iloc[:, 1:] =  test_Y_sort\n",
    "sample_sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
